<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Eduard Zamfir</title>

  <meta name="author" content="Eduard Zamfir">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="icon" type="image/png" href="images/img_eduardzamfir.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Eduard Zamfir</name>
              </p>
              <p> I am pursuing a PhD in Computer Science at the University of Wurzburg under the supervision of <a href=http://people.ee.ethz.ch/~timofter/>Prof. Radu Timofte</a>. </p>
              <p> I studied Computational Engineering at TU Darmstadt. There, I was a student research assistant at the 
                <a href="https://www.visinf.tu-darmstadt.de/visinf/news/vi_news_1.en.jsp">Visual Inference Lab</a> 
                led by 
                <a href="https://www.visinf.tu-darmstad.de/visinf/team_members/sroth/sroth.en.jsp">Prof. Stefan Roth</a>.
              </p>
             
              <p> Prior to that, I received a Bachelor in Mechanical Engineering with a focus on mechatronics and automotive engineering from TU Darmstadt.</p>
              <p style="text-align:center">
                <a href="mailto:eduard.zamfir2013@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://twitter.com/eduardSebasti20">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.de/citations?user=5-FIWKoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/eduard-zamfir-167660161/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/img_eduardzamfir.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/img_eduardzamfir.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research centers on addressing low-level vision problems and achieving efficient, photorealistic fusion of synthetic and real-world environments.
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:10%;vertical-align:middle">
              <img src="images/teaser_sqad.png" style="border-style: none" width="200" height="auto"/>
            </td>
            <td width="80%" valign="middle">
              <papertitle>SQAD: Automatic Smartphone Camera Quality Assessment and Benchmarking</papertitle>
              <br>
              Zilin Fang, Andrey Ignatov, <strong>Eduard Zamfir</strong>, Radu Timofte
              <br>
              <em>ICCV 2023</em>
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.pdf">Paper</a> / <a href="https://github.com/aiff22/SQAD">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:10%;vertical-align:middle">
              <img src="images/NTIRE_teaser.png" style="border-style: none" width="200" height="auto"/>
            </td>
            <td width="80%" valign="middle">
              <papertitle>Efficient Deep Models for Real-Time 4k Image Super-Resolution. NTIRE 2023 Benchmark and Report </papertitle>
              <br>
              Marcos V. Conde, <strong>Eduard Zamfir</strong>, Radu Timofte
              <br>
              <em>CVPRW 2023</em>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Conde_Efficient_Deep_Models_for_Real-Time_4K_Image_Super-Resolution._NTIRE_2023_CVPRW_2023_paper.pdf">Paper</a> / <a href="https://eduardzamfir.github.io/NTIRE23-RTSR/">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:10%;vertical-align:middle">
              <img src="images/towards_teaser.png" style="border-style: none" width="200" height="auto"/>
            </td>
            <td width="80%" valign="middle">
              <papertitle>Towards Real-Time 4K Image Super-Resolution</papertitle>
              <br>
              <strong>Eduard Zamfir</strong>, Marcos V. Conde, Radu Timofte
              <br>
              <em>CVPRW 2023</em>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Zamfir_Towards_Real-Time_4K_Image_Super-Resolution_CVPRW_2023_paper.pdf">Paper</a> / <a href="https://github.com/eduardzamfir/RT4KSR">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:10%;vertical-align:middle">
              <img src="images/main.gif" style="border-style: none" width="200" height="auto"/>
            </td>
            <td width="80%" valign="middle">
              <papertitle>Semantic Self-adaptation: Enhancing Generalization with a Single Sample</papertitle>
              <br>
              Sherwin Bahmani*, Oliver Hahn*, <strong>Eduard Zamfir*</strong>, Nikita Araslanov, Daniel Cremers, Stefan Roth
              <br>
              <em>TMLR 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2208.05788">Paper</a> / <a href="https://github.com/visinf/self-adaptive">Code</a>
              <br>
            </td>
          </tr>

        
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Service</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Reviewer:</b> TPAMI, CVPR
              </li>
              <li style="margin: 5px;"> 
                <b>Teaching Assistant:</b> Computer Vision, Image Processing and Computational Photography
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <br>
              <p>Website source code by <a href="http://jonbarron.info">Jon Barron</a>.
              </p>
              <br>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
